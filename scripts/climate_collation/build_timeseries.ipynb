{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d58150b-eb97-4678-a7f6-20c26e7eb1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# from ipywidgets import IntProgress\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281a2f1",
   "metadata": {},
   "source": [
    "> ## <span style=\"font-size: 25px; line-height: 1; color: #00b8d4; margin-right: 100px;\">&#9998;<span> <strong style=\"color: #00b8d4;\">Note</strong>\n",
    ">This notebook will extract climate timeseries from SILO NetCDF files and use them to create daily timeseries for rainfall runoff models. This includes PET and Rainfall data. Data will be written into a CSV file and will be constructed according to the data in the file rererence_table.csv. This table is built using the build_reference_table.ipynb notebook. \n",
    "> <br/><br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c2732a-39ed-4c31-b6f9-eeac09ac6d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = 'MW'        # one of ['BU', 'FI', 'MW', 'BU', 'BU', 'BU'] \n",
    "component = 'rain'    # should be rain or pet\n",
    "\n",
    "#start_year = 1970\n",
    "start_year = 2024\n",
    "finish_year = 2025\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The only thing that may be changed below is the path to the SILO NetCDF files\n",
    "\n",
    "reference_table = pd.read_csv('reference_table.csv')\n",
    "\n",
    "years = range(start_year, finish_year + 1)\n",
    "\n",
    "if component == 'rain' :\n",
    "    prefix = 'J:/TS/ClimateInputs/NetCDFdumps/Rainfall_Daily/'\n",
    "    suffix = '.daily_rain.nc'\n",
    "\n",
    "if component == 'pet' :\n",
    "    prefix = 'J:/TS/ClimateInputs/NetCDFdumps/ET_Morton_Wet/'\n",
    "    suffix = '.et_morton_wet.nc'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3755a3ca",
   "metadata": {},
   "source": [
    "> ## <span style=\"font-size: 25px; line-height: 1.0; color: #00b8d4; margin-right: 100px;\">&#9998;<span> <strong style=\"color: #00b8d4;\">Note</strong>\n",
    ">If everything is set up correctly. \n",
    "> <br/><br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed2e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_timeseries(region, year_range, component):\n",
    "    if component == 'rain' :\n",
    "        prefix = 'F:/TS/ClimateInputs/NetCDFdumps/Rainfall_Daily/'\n",
    "        suffix = '.daily_rain.nc'\n",
    "\n",
    "    if component == 'pet' :\n",
    "        prefix = 'F:/TS/ClimateInputs/NetCDFdumps/ET_Morton_Wet/'\n",
    "        suffix = '.et_morton_wet.nc'\n",
    "\n",
    "    timeseries = pd.DataFrame() \n",
    "\n",
    "    sub_reference_table = reference_table.query('region == @region')\n",
    "    subcatchment_list = sub_reference_table.subcatchment.unique()\n",
    "\n",
    "    for year in year_range:\n",
    "        print('running year ', year)\n",
    "\n",
    "        \n",
    "        filename = prefix + str(year) + suffix\n",
    "        ds = xr.open_dataset(filename)\n",
    "        ds.load()\n",
    "        datetimeindex = ds.indexes['time']\n",
    "        data = np.zeros((len(subcatchment_list), len(datetimeindex))) \n",
    "        subcatchment_list = sub_reference_table.subcatchment.unique().tolist()\n",
    "        \n",
    "        count = 0\n",
    "\n",
    "    #    for subcatchment in subcatchment_list:\n",
    "        for k in tqdm(range(len(subcatchment_list))):\n",
    "            subcatchment = subcatchment_list[k]\n",
    "            fragments = sub_reference_table.query('subcatchment == @subcatchment')\n",
    "            for i, j in fragments.iterrows():\n",
    "                xx = j.x\n",
    "                yy = j.y\n",
    "                fraction = j.grid_weight\n",
    "                if component ==  'rain' :\n",
    "                    data[count,:] += ds.sel(lon=xx,lat=yy,method='nearest').daily_rain.data * fraction\n",
    "                if component == 'pet' :\n",
    "                    data[count,:] += ds.sel(lon=xx,lat=yy,method='nearest').et_morton_wet.data * fraction\n",
    "            count += 1\n",
    "        \n",
    "        out = pd.DataFrame(data.T)\n",
    "        out.columns = subcatchment_list\n",
    "        out.set_index(datetimeindex, inplace=True)\n",
    "    #    out.to_csv(output_directory + str(year)+'.csv')\n",
    "\n",
    "        timeseries = pd.concat([timeseries, out])\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    timeseries.to_csv(region + '_' + component + '_timeseries.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62869c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running year  2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 551/551 [00:04<00:00, 120.78it/s]\n"
     ]
    }
   ],
   "source": [
    "#region_list = ['BM', 'FI', 'MW', 'BU', 'WT', 'CY']\n",
    "region_list = ['CY']\n",
    "component_list = ['rain', 'pet']\n",
    "\n",
    "for region in region_list :\n",
    "    for component in component_list :\n",
    "        print(' Running ', component, 'for ', region)\n",
    "        build_timeseries(region, years, component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143cdea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fdd077e-b2a2-4d7e-98e0-8af4941429e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running year  2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 151.42it/s]\n"
     ]
    }
   ],
   "source": [
    "timeseries = pd.DataFrame() \n",
    "\n",
    "sub_reference_table = reference_table.query('region == @region')\n",
    "subcatchment_list = sub_reference_table.subcatchment.unique()\n",
    "\n",
    "for year in years:\n",
    "    print('running year ', year)\n",
    "\n",
    "    \n",
    "    filename = prefix + str(year) + suffix\n",
    "    ds = xr.open_dataset(filename)\n",
    "    ds.load()\n",
    "    datetimeindex = ds.indexes['time']\n",
    "    data = np.zeros((len(subcatchment_list), len(datetimeindex))) \n",
    "    subcatchment_list = sub_reference_table.subcatchment.unique().tolist()\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "#    for subcatchment in subcatchment_list:\n",
    "    for k in tqdm(range(len(subcatchment_list))):\n",
    "        subcatchment = subcatchment_list[k]\n",
    "        fragments = sub_reference_table.query('subcatchment == @subcatchment')\n",
    "        for i, j in fragments.iterrows():\n",
    "            xx = j.x\n",
    "            yy = j.y\n",
    "            fraction = j.grid_weight\n",
    "            if component ==  'rain' :\n",
    "                data[count,:] += ds.sel(lon=xx,lat=yy,method='nearest').daily_rain.data * fraction\n",
    "            if component == 'pet' :\n",
    "                data[count,:] += ds.sel(lon=xx,lat=yy,method='nearest').et_morton_wet.data * fraction\n",
    "        count += 1\n",
    "    \n",
    "    out = pd.DataFrame(data.T)\n",
    "    out.columns = subcatchment_list\n",
    "    out.set_index(datetimeindex, inplace=True)\n",
    "#    out.to_csv(output_directory + str(year)+'.csv')\n",
    "\n",
    "    timeseries = pd.concat([timeseries, out])\n",
    "    clear_output(wait=True)\n",
    "\n",
    "timeseries.to_csv(region + '_' + component + '_timeseries.csv')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1bad8f-0eeb-4c58-b700-86f2739fda95",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" style=\"background: rgba(0,123,255,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #007bff; border-color: #007bff; padding-left: 10px; padding-right: 10px\">\n",
    "    <p class=\"title\">\n",
    "        <i style=\"font-size: 18px; color:#007bff;\"></i>\n",
    "        <b style=\"color: #007bff;\"> <span style=\"color: #007bff;\">&#8505;</span> Note</b>\n",
    "    </p>\n",
    "    <p>Running to following cell will run the climate collation step to prepare a set of files for importing into Source.\n",
    "    The resulting files will be written to the output directory</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4b1f993-1473-4fbc-adef-9eb80ba5c80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'MW_collation' already exists.\n"
     ]
    }
   ],
   "source": [
    "output_directory = region + '_collation/' \n",
    "directory_path = region + '_collation'\n",
    "\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "    # Create the directory\n",
    "    os.makedirs(directory_path)\n",
    "    print(f\"Directory '{directory_path}' was created.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory_path}' already exists.\")\n",
    "\n",
    "\n",
    "\n",
    "input_data = timeseries.copy()\n",
    "date_series = input_data.index\n",
    "\n",
    "if component == 'rain' :\n",
    "    for data in input_data.columns:\n",
    "        label = 'rainfall for ' + data\n",
    "        output_data = pd.DataFrame()\n",
    "        output_data['Date'] = date_series\n",
    "        output_data[label] = input_data[data].values\n",
    "        output_data.to_csv(output_directory + label + '.csv', index=False)\n",
    "\n",
    "if component == 'pet' :\n",
    "    for data in input_data.columns:\n",
    "        label = 'pet for ' + data\n",
    "        output_data = pd.DataFrame()\n",
    "        output_data['Date'] = date_series\n",
    "        output_data[label] = input_data[data].values\n",
    "        output_data.to_csv(output_directory + label + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0698495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_collation(region, component):\n",
    "\n",
    "    timeseries = pd.read_csv(region + '_' + component + '_timeseries.csv')\n",
    "    output_directory = region + '_collation/' \n",
    "    directory_path = region + '_collation'\n",
    "\n",
    "\n",
    "    if not os.path.exists(directory_path):\n",
    "        # Create the directory\n",
    "        os.makedirs(directory_path)\n",
    "        print(f\"Directory '{directory_path}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory_path}' already exists.\")\n",
    "\n",
    "\n",
    "\n",
    "    input_data = timeseries.copy()\n",
    "#    date_series = input_data.index\n",
    "    date_series = input_data['time']\n",
    "    del input_data['time']\n",
    "\n",
    "    if component == 'rain' :\n",
    "        for data in input_data.columns:\n",
    "            label = 'rainfall for ' + data\n",
    "            output_data = pd.DataFrame()\n",
    "            output_data['Date'] = date_series\n",
    "            output_data[label] = input_data[data].values\n",
    "            output_data.to_csv(output_directory + label + '.csv', index=False)\n",
    "\n",
    "    if component == 'pet' :\n",
    "        for data in input_data.columns:\n",
    "            label = 'pet for ' + data\n",
    "            output_data = pd.DataFrame()\n",
    "            output_data['Date'] = date_series\n",
    "            output_data[label] = input_data[data].values\n",
    "            output_data.to_csv(output_directory + label + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77dbfb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running  rain for  CY\n",
      "Directory 'CY_collation' was created.\n",
      " Running  pet for  CY\n",
      "Directory 'CY_collation' already exists.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# region_list = ['BM', 'FI', 'MW', 'BU', 'WT', 'CY']\n",
    "region_list = ['CY']\n",
    "#region_list = ['BM', 'FI', 'MW', 'BU', 'WT', 'CY']\n",
    "component_list = ['rain', 'pet']\n",
    "\n",
    "for region in region_list :\n",
    "    for component in component_list :\n",
    "        print(' Running ', component, 'for ', region)\n",
    "        do_collation(region, component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b4015c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
