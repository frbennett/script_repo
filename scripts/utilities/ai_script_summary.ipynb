{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66204d15",
   "metadata": {},
   "source": [
    "# AI Script Summary\n",
    "## Why use admonition notes in your notebooks\n",
    "Admonition notes (often just called \"admonitions\") in Jupyter Notebooks are special formatted blocks, typically implemented via Markdown extensions like MyST-Markdown or in tools like Jupyter Book, that allow you to create highlighted callouts in Markdown cells. They draw from reStructuredText (rST) styles and are used to emphasize certain content without disrupting the flow of the notebook.\n",
    "\n",
    "### Primary Reasons for Using Admonitions\n",
    "- **Highlighting Key Information**: They make it easy to spotlight tips, notes, or other advisory content in a visually distinct way, improving readability for educational materials, tutorials, or documentation. For example, a \"note\" admonition might provide additional context or a quick fact.\n",
    "- **Warnings and Cautions**: Admonitions are ideal for alerting users to potential pitfalls, errors, or important caveats, such as deprecated code or safety reminders in data analysis workflows. This helps prevent mistakes in interactive or shared notebooks.\n",
    "- **Structuring Complex Content**: In longer notebooks, they organize information like citations, figures, or side explanations, making the document more professional and easier to navigate. Tools like Jupyter Book extend this for book-like outputs.\n",
    "- **Customization and Rendering**: They support custom fences (e.g., :::) for better compatibility across interfaces, reducing clutter in raw Markdown while enabling rich rendering in HTML or PDF exports.\n",
    "\n",
    "The \"Note\" below is an example of the style for GBR Modelling script repo admonition note. Templated styles can be generated using the `generate_admonition_template` function in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe7e6b",
   "metadata": {},
   "source": [
    "## Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e80db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "from openai import OpenAI\n",
    "# import openai\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import pyperclip\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "import nbformat\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e532b28",
   "metadata": {},
   "source": [
    "## Processing \n",
    "\n",
    "These scripts collectively enable the automated reading, parsing, and AI-driven summarization of Jupyter notebooks by extracting content from code, markdown, and output cells, then using a conversational interface powered by an OpenAI-compatible API to generate initial summaries and handle follow-up queries while maintaining context.\n",
    "\n",
    "### Descriptions of Each Function / Class\n",
    "\n",
    "- **`read_notebook(notebook_path)`**: This function opens and parses a Jupyter notebook file (.ipynb) from the specified path using nbformat, returning a structured NotebookNode object that represents the notebook's contents in version 4 format.\n",
    "\n",
    "- **`extract_content(notebook)`**: This function iterates through all cells in a given notebook, extracting and formatting the source code from code cells (including any text outputs or results), as well as markdown content from markdown cells, and combines them into a single concatenated string separated by descriptive headers like \"# Code cell:\" or \"# Markdown:\".\n",
    "---\n",
    "- The **`NotebookSummarizer`** class is a Python wrapper that facilitates conversational summarization of Jupyter notebooks using the OpenAI API via OpenRouter, maintaining a persistent message history for context-aware initial summaries and follow-up queries while limiting history length to manage token usage.\n",
    "\n",
    "- **`__init__(self, api_key, model=\"openai/gpt-4o\", max_history=10)`** (method of NotebookSummarizer): This constructor initializes the NotebookSummarizer class by creating an OpenAI client configured for OpenRouter, setting the model and history limit, and starting the conversation history with a system prompt that instructs the AI to act as an expert in summarizing Jupyter notebooks while maintaining context.\n",
    "\n",
    "- **`initial_summarize(self, prompt)`** (method of NotebookSummarizer): This method begins the summarization process by optionally copying the provided prompt (notebook content) to the system clipboard, appending it as a user message to the conversation history, and then calling the internal _get_response method to obtain and return the AI's initial summary.\n",
    "\n",
    "- **`follow_up(self, query)`** (method of NotebookSummarizer): This method allows for subsequent interactions by appending a new user query to the history, trimming the history if it exceeds the maximum length by removing the oldest user-assistant pairs (while preserving the system prompt), and then retrieving and returning the AI's response based on the updated context.\n",
    "\n",
    "- **`_get_response(self)`** (method of NotebookSummarizer): This private method handles the core API interaction by sending the current conversation history to the OpenAI chat completions endpoint via the configured client, extracting the assistant's response text (with fallback handling for different response formats), appending it to the history, and returning it, while including optional headers and a high max_tokens limit for detailed outputs; it raises an exception if the extraction fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53aaec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_notebook(notebook_path):\n",
    "    \"\"\"\n",
    "    Reads a Jupyter notebook file and returns its content.\n",
    "    \n",
    "    Args:\n",
    "        notebook_path (str): Path to the .ipynb file\n",
    "        \n",
    "    Returns:\n",
    "        nbformat.NotebookNode: Parsed notebook object\n",
    "    \"\"\"\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as file:\n",
    "        return nbformat.read(file, as_version=4)\n",
    "    \n",
    "\n",
    "def extract_content(notebook):\n",
    "    \"\"\"\n",
    "    Extracts text from code and markdown cells in a notebook.\n",
    "    \n",
    "    Args:\n",
    "        notebook (nbformat.NotebookNode): The notebook to process\n",
    "        \n",
    "    Returns:\n",
    "        str: Combined content from all cells\n",
    "    \"\"\"\n",
    "    content_parts = []\n",
    "    \n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'code':\n",
    "            # Include both the code and any text outputs\n",
    "            content_parts.append(f\"# Code cell:\\n{cell.source}\\n\")\n",
    "            if 'outputs' in cell and cell.outputs:\n",
    "                for output in cell.outputs:\n",
    "                    if output.output_type == 'stream' and 'text' in output:\n",
    "                        content_parts.append(f\"# Output:\\n{output.text}\\n\")\n",
    "                    elif output.output_type == 'execute_result' and 'data' in output:\n",
    "                        if 'text/plain' in output.data:\n",
    "                            content_parts.append(f\"# Result:\\n{output.data['text/plain']}\\n\")\n",
    "        elif cell.cell_type == 'markdown':\n",
    "            content_parts.append(f\"# Markdown:\\n{cell.source}\\n\")\n",
    "    \n",
    "    return \"\\n\".join(content_parts)\n",
    "\n",
    "\n",
    "class NotebookSummarizer:\n",
    "    \"\"\"\n",
    "    A conversational wrapper for summarizing notebooks with persistent context.\n",
    "    Manages message history for follow-up queries.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key, model=\"openai/gpt-4o\", max_history=10):\n",
    "        self.client = OpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=api_key,\n",
    "        )\n",
    "        self.model = model\n",
    "        self.history = []  # List of {\"role\": str, \"content\": str}\n",
    "        self.max_history = max_history  # Limit to prevent token overflow\n",
    "        # Initial system message\n",
    "        system_prompt = 'You are an expert at analyzing and summarizing Jupyter notebooks for data science and programming contexts. Maintain context from previous interactions.'\n",
    "        self.history.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    def initial_summarize(self, prompt):\n",
    "        \"\"\"\n",
    "        Start the conversation with the initial notebook content.\n",
    "        \n",
    "        Args:\n",
    "            content (str): The notebook content to summarize.\n",
    "        \"\"\"\n",
    "        # Build initial prompt (your original, but without repeating in follow-ups)\n",
    "\n",
    "        pyperclip.copy(prompt)  # Optional: Copy for manual use\n",
    "        self.history.append({\"role\": \"user\", \"content\": prompt})\n",
    "        return self._get_response()\n",
    "    \n",
    "    def follow_up(self, query):\n",
    "        \"\"\"\n",
    "        Send a follow-up query using the existing context.\n",
    "        \n",
    "        Args:\n",
    "            query (str): The follow-up question or instruction (e.g., \"Explain the ARD method in more detail\").\n",
    "        \n",
    "        Returns:\n",
    "            str: The assistant's response.\n",
    "        \"\"\"\n",
    "        self.history.append({\"role\": \"user\", \"content\": query})\n",
    "        # Trim history if too long (remove oldest user/assistant pairs)\n",
    "        while len(self.history) > self.max_history + 1:  # +1 for system\n",
    "            self.history = [self.history[0]] + self.history[2:]  # Skip first user/assistant pair\n",
    "        return self._get_response()\n",
    "    \n",
    "    def _get_response(self):\n",
    "        \"\"\"\n",
    "        Internal method to call the API and extract response.\n",
    "        Uses fallback extraction for robustness.\n",
    "        \"\"\"\n",
    "        def extract_text_from_response(response_obj):\n",
    "            # Same as previous: Extract from ChatCompletion or raw JSON\n",
    "            if hasattr(response_obj, 'choices') and response_obj.choices:\n",
    "                return response_obj.choices[0].message.content\n",
    "            # Fallback recursion (omitted for brevity; use the previous extract_text_from_response)\n",
    "            return \"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.history,\n",
    "                extra_headers={\n",
    "                    \"HTTP-Referer\": \"your-app-url\",  # Optional\n",
    "                    \"X-Title\": \"Notebook Summarizer\",\n",
    "                },\n",
    "                max_tokens=9000,\n",
    "            )\n",
    "            assistant_response = extract_text_from_response(response)\n",
    "            if not assistant_response:\n",
    "                raise ValueError(\"No text extracted from response\")\n",
    "            # Append to history\n",
    "            self.history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "            return assistant_response\n",
    "        except Exception as e:\n",
    "            # Fallback to alpha endpoint if needed (adapt as in previous code)\n",
    "            print(f\"API call failed: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0deeab",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "The `prompt_prefix` is a structured template designed for AI analysis of Jupyter notebooks, directing the generation of a detailed summary organized under six specific headings. \n",
    "\n",
    "In contrast, the `definition_text` provides concise instructions for creating a brief 2-3 line notebook summary to insert into a predefined HTML snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d9069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = f\"\"\"\n",
    "        Please analyze the following Jupyter notebook content and provide a comprehensive summary.\n",
    "        Organise your response under the following headings:\n",
    "        1. The main purpose and objectives of the notebook\n",
    "        2. Key code logic and functions implemented\n",
    "        3. Important findings or results shown in outputs\n",
    "        4. Overall structure and flow\n",
    "        5. Instructions for use\n",
    "        6. Theoretical Description of Methods\n",
    "\n",
    "        Consistently format the heading like \"## 1. The main purpose and objectives of the notebook\\n\\n\" \n",
    "\n",
    "        Provide a bibliography of web references if used.\n",
    "\n",
    "        Write mathematical expressions using proper LaTeX syntax. Format as inline ($) or display ($$) equations. Do not escape backslashes.\n",
    "        \n",
    "        Be careful to avoid KaTeX parse errors like 'Expected EOF'.\n",
    "\n",
    "        Avoid overuse of bullet or numbered lists.\n",
    "\n",
    "        At the end, add an interesting and possibly relevant fact with a reference if available.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "definition_text = \"\"\"\n",
    "    write a short two to three line summary of the notebook and paste it into the following html snippet\n",
    "    relpacing the field '[short_summary]'\n",
    "\n",
    "> ## <strong style=\"color:#00b8d4; font-size:28px;\">AI Script Summary</strong>\n",
    "> <span style=\"color:#757575; font-size:18px; display:block; margin-top:1px;\">[short_summary] </span> <br/><br/>\n",
    "> <strong>Authors:</strong> F. R. Bennett &nbsp;&nbsp; <br/><br/>\n",
    "> <strong>Date:</strong> 17/10/25  &nbsp;&nbsp; <br/><br/>\n",
    "> <strong>Version:</strong> 1.0<br/><br/>\n",
    "> \n",
    "> <button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples/ishigami_new_legendre.ipynb', 'download')\">Download File</button>\n",
    "> \n",
    "><button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples', 'download')\">Download Folder</button>\n",
    ">\n",
    "><button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples/ishigami_new_legendre.ipynb', 'open')\">Open on GitHub</button>\n",
    "> <br/><br/>\n",
    "\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.0/jszip.min.js\"></script>\n",
    "<script>\n",
    "async function handleGitHubAction(owner, repo, path, action) {\n",
    "  const apiUrl = `https://api.github.com/repos/${owner}/${repo}/contents/${path}`;\n",
    "  const githubUrl = `https://github.com/${owner}/${repo}/tree/main/${path}`;\n",
    "\n",
    "  if (action === 'open') {\n",
    "    window.open(githubUrl, '_blank');\n",
    "    return;\n",
    "  }\n",
    "\n",
    "  const response = await fetch(apiUrl);\n",
    "  const data = await response.json();\n",
    "\n",
    "  if (Array.isArray(data)) {\n",
    "    // Directory download\n",
    "    const zip = new JSZip();\n",
    "    for (const file of data) {\n",
    "      if (file.type === \"file\") {\n",
    "        const fileRes = await fetch(file.download_url);\n",
    "        const content = await fileRes.text();\n",
    "        zip.file(file.name, content);\n",
    "      }\n",
    "    }\n",
    "    const blob = await zip.generateAsync({ type: \"blob\" });\n",
    "    const link = document.createElement(\"a\");\n",
    "    link.href = URL.createObjectURL(blob);\n",
    "    link.download = `${path.split('/').pop()}.zip`;\n",
    "    link.click();\n",
    "  } else if (data.type === \"file\") {\n",
    "    // Single file download\n",
    "    const decoded = atob(data.content.replace(/\\n/g, ''));\n",
    "    const blob = new Blob([decoded], { type: 'application/octet-stream' });\n",
    "    const link = document.createElement('a');\n",
    "    link.href = URL.createObjectURL(blob);\n",
    "    link.download = data.name;\n",
    "    link.click();\n",
    "  } else {\n",
    "    alert(\"Unsupported content type or path not found.\");\n",
    "  }\n",
    "}\n",
    "</script>\n",
    "\n",
    "\n",
    "                    \"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111450e6",
   "metadata": {},
   "source": [
    "<div class=\"admonition example\" name=\"html-admonition\" style=\"background: rgba(92,107,192,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #5c6bc0; border-color: #5c6bc0; padding-left: 10px; padding-right: 10px;\">\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#5c6bc0;\">&#128221;</i>\n",
    "    <b style=\"color: #5c6bc0;\">Example</b>\n",
    "</p>\n",
    "<p>\n",
    "The <code>summarise_this</code> function serves as a demonstration of the previously defined <code>NotebookSummarizer</code> class and related utilities by taking a path to a Jupyter notebook file and an optional AI model (defaulting to \"google/gemini-2.5-flash-lite\"), reading and extracting its content, constructing a prompt with a predefined prefix, and generating both an initial summary and a follow-up definition response using the summarizer. \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f521928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_this(NOTEBOOK_PATH, model=\"google/gemini-2.5-flash-lite\"):\n",
    "    # Configuration\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")  # Get API key from environment\n",
    "\n",
    "    if not OPENAI_API_KEY:\n",
    "        raise ValueError(\"Please set the OPENAI_API_KEY environment variable\")\n",
    "\n",
    "    if not os.path.exists(NOTEBOOK_PATH):\n",
    "        raise FileNotFoundError(f\"Notebook file not found: {NOTEBOOK_PATH}\")\n",
    "\n",
    "    # Read and process the notebook\n",
    "    print(\"Reading notebook...\")\n",
    "    notebook = read_notebook(NOTEBOOK_PATH)\n",
    "\n",
    "    print(\"Extracting content...\")\n",
    "    notebook_content = extract_content(notebook)\n",
    "\n",
    "    # Build prompt\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_prefix}\n",
    "            \n",
    "    Notebook content:\n",
    "    {notebook_content}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    summarizer = NotebookSummarizer(api_key=OPENAI_API_KEY, model=model)\n",
    "    summary = summarizer.initial_summarize(prompt)\n",
    "\n",
    "    \n",
    "    definition_response = summarizer.follow_up(definition_text)\n",
    "\n",
    "    # Usage\n",
    "\n",
    "    return summary, definition_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba22ed8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a2b358",
   "metadata": {},
   "source": [
    "<div class=\"admonition example\" name=\"html-admonition\" style=\"background: rgba(92,107,192,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #5c6bc0; border-color: #5c6bc0; padding-left: 10px; padding-right: 10px;\">\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#5c6bc0;\">&#128221;</i>\n",
    "    <b style=\"color: #5c6bc0;\">Example</b>\n",
    "</p>\n",
    "<p>\n",
    "Now, pulling it all together and building a summary of this notebook. The final composed result is displayed using the <code>Markdown</code> function and is saved to the clipboard using <code>pyperclip</code> to be pasted directly into a markdown document or cell. \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ff54069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading notebook...\n",
      "Extracting content...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " \n",
       "> ## <strong style=\"color:#00b8d4; font-size:28px;\">AI Script Summary</strong>\n",
       "> <span style=\"color:#757575; font-size:18px; display:block; margin-top:1px;\">This notebook develops a Python tool for automating AI-driven summarization of Jupyter notebooks using OpenRouter's OpenAI-compatible API, parsing .ipynb files to extract code, markdown, and outputs into prompts for structured analyses. It includes a NotebookSummarizer class for conversational interactions with history management, demonstrates self-summarization, and provides offline prompt generation, enhancing documentation with admonition notes and HTML templates for interactive GitHub integration. The framework streamlines creating professional overviews for data science scripts, supporting follow-up queries while maintaining context.</span> <br/><br/>\n",
       "> <strong>Authors:</strong> F. R. Bennett &nbsp;&nbsp; <br/><br/>\n",
       "> <strong>Date:</strong> 17/10/25  &nbsp;&nbsp; <br/><br/>\n",
       "> <strong>Version:</strong> 1.0<br/><br/>\n",
       "> \n",
       "> <button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples/ishigami_new_legendre.ipynb', 'download')\">Download File</button>\n",
       "> \n",
       "><button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples', 'download')\">Download Folder</button>\n",
       ">\n",
       "><button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples/ishigami_new_legendre.ipynb', 'open')\">Open on GitHub</button>\n",
       "> <br/><br/>\n",
       "\n",
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.0/jszip.min.js\"></script>\n",
       "<script>\n",
       "async function handleGitHubAction(owner, repo, path, action) {\n",
       "  const apiUrl = `https://api.github.com/repos/${owner}/${repo}/contents/${path}`;\n",
       "  const githubUrl = `https://github.com/${owner}/${repo}/tree/main/${path}`;\n",
       "\n",
       "  if (action === 'open') {\n",
       "    window.open(githubUrl, '_blank');\n",
       "    return;\n",
       "  }\n",
       "\n",
       "  const response = await fetch(apiUrl);\n",
       "  const data = await response.json();\n",
       "\n",
       "  if (Array.isArray(data)) {\n",
       "    // Directory download\n",
       "    const zip = new JSZip();\n",
       "    for (const file of data) {\n",
       "      if (file.type === \"file\") {\n",
       "        const fileRes = await fetch(file.download_url);\n",
       "        const content = await fileRes.text();\n",
       "        zip.file(file.name, content);\n",
       "      }\n",
       "    }\n",
       "    const blob = await zip.generateAsync({ type: \"blob\" });\n",
       "    const link = document.createElement(\"a\");\n",
       "    link.href = URL.createObjectURL(blob);\n",
       "    link.download = `${path.split('/').pop()}.zip`;\n",
       "    link.click();\n",
       "  } else if (data.type === \"file\") {\n",
       "    // Single file download\n",
       "    const decoded = atob(data.content.replace(/\\n/g, ''));\n",
       "    const blob = new Blob([decoded], { type: 'application/octet-stream' });\n",
       "    const link = document.createElement('a');\n",
       "    link.href = URL.createObjectURL(blob);\n",
       "    link.download = data.name;\n",
       "    link.click();\n",
       "  } else {\n",
       "    alert(\"Unsupported content type or path not found.\");\n",
       "  }\n",
       "}\n",
       "</script>\n",
       "# Detailed Summary\n",
       "---\n",
       "## 1. The main purpose and objectives of the notebook\n",
       "\n",
       "This notebook develops and demonstrates a Python-based tool for automating the summarization of Jupyter notebooks using AI, specifically through an OpenAI-compatible API via OpenRouter. Its primary purpose is to enable users to parse notebook files, extract content from code, markdown, and output cells, and generate structured summaries or brief descriptions that can be integrated into documentation, HTML snippets, or follow-up analyses. Objectives include improving notebook documentation with admonition notes for better readability, supporting conversational AI interactions to maintain context across queries, providing an offline prompt-building alternative, and facilitating self-referential testing by summarizing the notebook itself. Overall, it aims to streamline the process of creating professional overviews for data science scripts in repositories, enhancing accessibility and reusability without manual effort.\n",
       "\n",
       "## 2. Key code logic and functions implemented\n",
       "\n",
       "The notebook imports essential libraries such as openai for API access, IPython.display for rendering Markdown, pyperclip for clipboard operations, os and requests for file handling, and nbformat for notebook parsing. It defines read_notebook, which opens a .ipynb file and parses it into a NotebookNode object using nbformat.read with UTF-8 encoding. The extract_content function loops through notebook cells: for code cells, it appends the source prefixed by \"# Code cell:\", adds stream outputs as \"# Output:\" and execution results as \"# Result:\" if available; for markdown cells, it appends the source prefixed by \"# Markdown:\", then joins all parts into a single string. The NotebookSummarizer class initializes an OpenAI client configured for OpenRouter with a specified model and max_history limit, starts a conversation history with a system prompt defining the AI as a notebook summarization expert, and manages message persistence. Its initial_summarize method copies the input prompt to the clipboard, appends it as a user message to history, and invokes _get_response to call the API. The follow_up method appends a query as a user message, trims excess history by removing the oldest user-assistant pairs while retaining the system prompt, and retrieves a response. The private _get_response method submits the history to chat.completions.create with optional headers and a high max_tokens value, extracts the assistant's content (with fallback checks), appends it to history, and handles exceptions like API failures. Prompt templates include prompt_prefix for guiding comprehensive, heading-structured summaries with LaTeX instructions, and definition_text for generating short 2-3 line overviews to insert into an HTML snippet with GitHub download buttons using JSZip for zipping directories. The summarise_this function orchestrates usage by validating the API key and file path, reading and extracting notebook content, building a prefixed prompt, instantiating the summarizer, generating an initial summary, following up for a definition response, and returning both. Additional code cells demonstrate execution on the notebook itself, composing results for display via Markdown and clipboard copying, with an offline variant that builds and copies the prompt without API calls.\n",
       "\n",
       "## 3. Important findings or results shown in outputs\n",
       "\n",
       "Outputs primarily showcase the tool's self-application, with console messages confirming \"Reading notebook...\" and \"Extracting content...\" phases. The core result is an IPython Markdown object rendering a composed summary: it begins with an HTML-formatted \"AI Script Summary\" block inserting a 3-line AI-generated brief describing the notebook as an AI tool for content extraction and summarization with admonition enhancements, followed by a detailed, heading-organized analysis mirroring the requested structure. This self-summary validates the pipeline's efficacy, producing coherent, context-aware outputs that blend brief overviews with in-depth breakdowns, including admonition explanations and prompt templates. A follow-up output displays the populated HTML snippet with styled authorship, date, version, and interactive GitHub buttons for file/folder downloads or opening, powered by JavaScript fetching from the GitHub API and JSZip for zipping. The offline option copies a ready-to-paste prompt, enabling manual AI interaction, while the notebook's embedded example result from a Grok chatbot reiterates the structured summary, confirming cross-model compatibility. No quantitative findings emerge, but the outputs highlight the tool's robustness in generating professional, clipboard-ready documentation.\n",
       "\n",
       "## 4. Overall structure and flow\n",
       "\n",
       "The notebook opens with markdown introducing admonition notes, explaining their role in highlighting information, issuing warnings, and structuring content, referencing tools like MyST-Markdown and Jupyter Book. It transitions to libraries import, followed by a markdown overview of processing functions and the NotebookSummarizer class. Code cells implement read_notebook, extract_content, and the class with its methods, emphasizing history management and API resilience. Subsequent markdown describes prompt_prefix for detailed summaries and definition_text for HTML briefs, accompanied by admonition examples. The summarise_this function is defined, then demonstrated in a code cell targeting the notebook itself, using a Grok model to generate and display results via Markdown display and pyperclip copying. An offline section mirrors this flow without API calls, copying prompts directly. Admonition blocks intersperse explanations, culminating in further copying utilities and a final formatted HTML output. The flow progresses logically from conceptual foundations and admonition rationale, through implementation, prompt design, and demonstration, to practical extensions like offline use and result composition, ensuring a tutorial-like progression for users.\n",
       "\n",
       "## 5. Instructions for use\n",
       "\n",
       "Set the environment variable OPENROUTER_API_KEY with a valid OpenRouter API key to enable online summarization; without it, use the offline prompt-copying mode. Specify the path to a target .ipynb file in the NOTEBOOK_PATH variable or as an argument to summarise_this, optionally customizing the model (e.g., \"x-ai/grok-4-fast\" or \"google/gemini-2.5-flash-lite\"). Run cells sequentially: imports first, then function definitions, prompt setups, and the demonstration cell to process the notebook, generate summaries, and output results as Markdown with clipboard copies. For conversational depth, instantiate NotebookSummarizer separately and chain initial_summarize with follow_up calls for queries like method explanations, adjusting max_history for longer contexts. In offline mode, execute the extraction code to copy a pre-built prompt to the clipboard, then paste it into an AI chatbot interface. Adapt the HTML in definition_text for custom repositories by updating GitHub owner/repo paths and button actions. Test on the notebook itself for validation, and integrate outputs into markdown documents or web pages for documentation; ensure JSZip library loads for HTML button functionality in rendered environments.\n",
       "\n",
       "## 6. Theoretical Description of Methods\n",
       "\n",
       "The approach centers on programmatic parsing of Jupyter notebooks as JSON-structured documents via nbformat, which decomposes content into typed cells (code for executable Python with outputs, markdown for formatted text), allowing systematic extraction that captures semantic layers like code intent, textual explanations, and runtime results without execution. This extraction concatenates elements with descriptive delimiters to form a linear prompt suitable for large language models, which process it through transformer-based architectures to infer high-level themes, logic flows, and implications. The conversational wrapper employs a message history simulating multi-turn dialogue, with token-efficient trimming to sustain context akin to memory-augmented reasoning, preventing dilution from irrelevant prior exchanges while anchoring to an expert system prompt. Prompt engineering structures outputs via explicit headings and constraints (e.g., LaTeX for equations, list avoidance), leveraging the model's generative capabilities for synthesized summaries that emulate human analysis. Follow-up mechanisms build on this by injecting queries into the latent context, enabling iterative refinement without restarting, grounded in natural language understanding principles. The offline variant decouples parsing from inference, treating extraction as a preprocessing step for external LLMs, while HTML integration applies templating for reproducible, interactive outputs, drawing from web development patterns for dynamic content delivery.\n",
       "\n",
       "No web references were used in this summary.\n",
       "\n",
       "An interesting and possibly relevant fact: Admonition blocks in Jupyter, inspired by reStructuredText, enhance accessibility by providing visual cues similar to how screen readers interpret semantic HTML elements, improving usability for diverse audiences in technical documentation. [Reference: Jupyter Book Documentation on Admonitions, https://jupyterbook.org/content/metadata.html#admonitions]\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=\"x-ai/grok-4-fast\"\n",
    "notebook_to_summarise = 'D:/gdrive/My Drive/Work Projects/Coding_Projects/script_repo/scripts/utilities/ai_script_summary.ipynb'  # running this on a copy of the current notebook\n",
    "\n",
    "summary, definition_response = summarise_this(notebook_to_summarise, model=model)\n",
    "\n",
    "all_result = f\"\"\" \n",
    "{definition_response}\n",
    "# Detailed Summary\n",
    "---\n",
    "{summary}\n",
    "\"\"\"\n",
    "pyperclip.copy(all_result)\n",
    "Markdown(all_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19c6327",
   "metadata": {},
   "source": [
    "## Offline option\n",
    "If you don't have access to an appropriate API for sumbitting LLM queries, you can easily use the \n",
    "offline option as demonstrated below. Simply build the prompt using the extraction tools and copy and paste it into \n",
    "a chatbot. In this example, the prompt is automatically copied to the clipboard using <code>pyperclip</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63cce0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading notebook...\n",
      "Extracting content...\n"
     ]
    }
   ],
   "source": [
    "NOTEBOOK_PATH = 'D:/gdrive/My Drive/Work Projects/Coding_Projects/script_repo/scripts/utilities/ai_script_summary.ipynb'\n",
    "# Read and process the notebook\n",
    "print(\"Reading notebook...\")\n",
    "notebook = read_notebook(NOTEBOOK_PATH)\n",
    "\n",
    "print(\"Extracting content...\")\n",
    "notebook_content = extract_content(notebook)\n",
    "\n",
    "# Build prompt\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{prompt_prefix}\n",
    "        \n",
    "Notebook content:\n",
    "{notebook_content}\n",
    "\n",
    "\"\"\"\n",
    "pyperclip.copy(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee8835",
   "metadata": {},
   "source": [
    "# Here is the result using the Grok chatbot\n",
    "\n",
    "--- \n",
    "\n",
    "\n",
    "## 1. The main purpose and objectives of the notebook\n",
    "\n",
    "This notebook aims to demonstrate and implement an automated system for reading, parsing, and generating AI-driven summaries of Jupyter notebooks, leveraging an OpenAI-compatible API through OpenRouter to produce structured overviews and handle contextual follow-up queries. Its objectives include facilitating the creation of concise summaries for documentation or sharing purposes, enhancing notebook readability with admonition notes, and providing a reusable framework for analyzing notebook content in data science and programming contexts, ultimately streamlining the process of extracting insights from complex interactive documents.\n",
    "\n",
    "## 2. Key code logic and functions implemented\n",
    "\n",
    "The notebook defines several core functions and a class to handle notebook processing and summarization. The read_notebook function loads a .ipynb file using nbformat and returns a NotebookNode object. The extract_content function iterates over the notebook's cells, appending markdown sources prefixed with \"# Markdown:\" and code sources with \"# Code cell:\", while also incorporating text outputs or execution results from code cells under headers like \"# Output:\" or \"# Result:\". The NotebookSummarizer class initializes an OpenAI client pointed at OpenRouter's API, maintains a conversation history limited by max_history to avoid token overflow, and starts with a system prompt for expert summarization. Its initial_summarize method copies the prompt to the clipboard, appends it to history, and fetches an AI response. The follow_up method adds new queries, trims history if needed by removing oldest pairs while keeping the system prompt, and retrieves responses. The private _get_response method sends the history to the chat completions endpoint with high max_tokens for detailed outputs, extracts the assistant's content with fallback handling, and appends it to history. Additionally, the summarise_this function orchestrates the process by reading a notebook, extracting content, building a prefixed prompt, generating an initial summary, and following up with a short definition for HTML insertion. Prompt templates like prompt_prefix guide structured summaries, and definition_text directs brief overviews for HTML snippets.\n",
    "\n",
    "## 3. Important findings or results shown in outputs\n",
    "\n",
    "The notebook's outputs primarily demonstrate successful execution of its summarization pipeline on itself, showing progress messages like \"Reading notebook...\" and \"Extracting content...\" during processing. The key result is an IPython Markdown object displaying the composed summary, which includes a short AI-generated description inserted into an HTML template for a visually styled \"AI Script Summary\" block, followed by a detailed summary under headings. This self-referential summarization validates the tool's functionality, producing coherent outputs that blend brief overviews with comprehensive analyses, and copies the full result to the clipboard for easy pasting. An offline option re-extracts content and copies the prompt, enabling manual AI interaction outside the script.\n",
    "\n",
    "## 4. Overall structure and flow\n",
    "\n",
    "The notebook begins with markdown explanations of admonition notes, their benefits for highlighting information, warnings, and structuring content, including an example template generator mention. It then lists imported libraries for API interaction, display, clipboard handling, file operations, and notebook parsing. A markdown section describes the processing functions and NotebookSummarizer class in detail. Code cells implement these components, followed by prompt definitions for structured summaries and HTML-inserted briefs. Admonition blocks provide examples of the summarizer in action, leading to the summarise_this function demonstration, which processes the notebook itself and displays the result via Markdown. The flow concludes with an offline prompt copying option and additional clipboard and file-saving utilities, creating a logical progression from concepts to implementation, demonstration, and utility extensions.\n",
    "\n",
    "## 5. Instructions for use\n",
    "\n",
    "To use this notebook, ensure an OpenRouter API key is set as the environment variable OPENROUTER_API_KEY. Specify a notebook path in the summarise_this function or directly in code cells, optionally selecting a model like \"x-ai/grok-4-fast\". Run the cells sequentially to read the target notebook, extract its content, generate an initial structured summary via AI, and produce a follow-up brief for HTML integration. The result is displayed as Markdown and copied to the clipboard for pasting into documents; for offline use, copy the built prompt and input it manually into an AI interface. Customize the max_history parameter in NotebookSummarizer for longer contexts if needed, and adapt the HTML template in definition_text for different styling or buttons.\n",
    "\n",
    "## 6. Theoretical Description of Methods\n",
    "\n",
    "The methods rely on structured parsing of Jupyter notebooks via nbformat, which represents notebooks as JSON-like objects with cells categorized by type, enabling systematic content extraction that preserves code, markdown, and outputs for holistic analysis. The summarization leverages large language models through a conversational API, where a system prompt establishes the AI's role as an expert analyzer, and user messages append notebook content or queries to maintain context across interactions. History management prevents token overflow by pruning older exchanges, ensuring efficient multi-turn dialogues akin to chain-of-thought reasoning in prompt engineering. Prompt templates enforce output organization, drawing from natural language processing techniques to guide generation toward comprehensive, heading-based summaries while incorporating LaTeX for mathematical fidelity and avoiding parsing errors. This approach combines document parsing with contextual AI inference, facilitating semantic understanding and synthesis of notebook elements without manual intervention.\n",
    "\n",
    "Jupyter notebooks, originally called IPython notebooks, were renamed in 2015 as part of Project Jupyter to reflect language-agnostic support beyond Python. [Reference: Project Jupyter Documentation, https://docs.jupyter.org/en/latest/]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c58b7",
   "metadata": {},
   "source": [
    "<div class=\"admonition example\" name=\"html-admonition\" style=\"background: rgba(92,107,192,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #5c6bc0; border-color: #5c6bc0; padding-left: 10px; padding-right: 10px;\">\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#5c6bc0;\">&#128221;</i>\n",
    "    <b style=\"color: #5c6bc0;\">Example</b>\n",
    "</p>\n",
    "<p>\n",
    "We can also apply the same strategy for building the heading summary by continuing the chat with the summary prompt. \n",
    "It can simply be copied to the clipboard using <code>pyperclip</code> and pasted directly into the same chat session \n",
    "as opened previously\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffb8f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy(definition_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f484b702",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4; border-color: #00b8d4; padding-left: 10px; padding-right: 10px;\">\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00b8d4;\">&#9998;</i>\n",
    "    <b style=\"color: #00b8d4;\">Note</b>\n",
    "</p>\n",
    "<p>\n",
    "Here is the formatted output. \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6098ead",
   "metadata": {},
   "source": [
    "> ## <strong style=\"color:#00b8d4; font-size:28px;\">AI Script Summary</strong>\n",
    "> <span style=\"color:#757575; font-size:18px; display:block; margin-top:1px;\">This notebook implements an AI-driven tool for summarizing Jupyter notebooks, featuring functions to read and extract content from .ipynb files, and a conversational class using OpenAI API for generating initial summaries and handling follow-up queries. It demonstrates the process by self-summarizing, producing structured outputs with prompts for detailed analysis under specific headings. The tool enhances documentation with admonition notes and HTML templates for visually appealing summaries.</span> <br/><br/>\n",
    "> <strong>Authors:</strong> F. R. Bennett &nbsp;&nbsp; <br/><br/>\n",
    "> <strong>Date:</strong> 17/10/25  &nbsp;&nbsp; <br/><br/>\n",
    "> <strong>Version:</strong> 1.0<br/><br/>\n",
    "> \n",
    "> <button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples/ishigami_new_legendre.ipynb', 'download')\">Download File</button>\n",
    "> \n",
    "><button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples', 'download')\">Download Folder</button>\n",
    ">\n",
    "><button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples/ishigami_new_legendre.ipynb', 'open')\">Open on GitHub</button>\n",
    "> <br/><br/>\n",
    "\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.0/jszip.min.js\"></script>\n",
    "<script>\n",
    "async function handleGitHubAction(owner, repo, path, action) {\n",
    "  const apiUrl = `https://api.github.com/repos/${owner}/${repo}/contents/${path}`;\n",
    "  const githubUrl = `https://github.com/${owner}/${repo}/tree/main/${path}`;\n",
    "\n",
    "  if (action === 'open') {\n",
    "    window.open(githubUrl, '_blank');\n",
    "    return;\n",
    "  }\n",
    "\n",
    "  const response = await fetch(apiUrl);\n",
    "  const data = await response.json();\n",
    "\n",
    "  if (Array.isArray(data)) {\n",
    "    // Directory download\n",
    "    const zip = new JSZip();\n",
    "    for (const file of data) {\n",
    "      if (file.type === \"file\") {\n",
    "        const fileRes = await fetch(file.download_url);\n",
    "        const content = await fileRes.text();\n",
    "        zip.file(file.name, content);\n",
    "      }\n",
    "    }\n",
    "    const blob = await zip.generateAsync({ type: \"blob\" });\n",
    "    const link = document.createElement(\"a\");\n",
    "    link.href = URL.createObjectURL(blob);\n",
    "    link.download = `${path.split('/').pop()}.zip`;\n",
    "    link.click();\n",
    "  } else if (data.type === \"file\") {\n",
    "    // Single file download\n",
    "    const decoded = atob(data.content.replace(/\n",
    "/g, ''));\n",
    "    const blob = new Blob([decoded], { type: 'application/octet-stream' });\n",
    "    const link = document.createElement('a');\n",
    "    link.href = URL.createObjectURL(blob);\n",
    "    link.download = data.name;\n",
    "    link.click();\n",
    "  } else {\n",
    "    alert(\"Unsupported content type or path not found.\");\n",
    "  }\n",
    "}\n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4bb581",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
