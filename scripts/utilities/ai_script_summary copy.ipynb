{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66204d15",
   "metadata": {},
   "source": [
    "# AI Script Summary\n",
    "## Why use admonition notes in your notebooks\n",
    "Admonition notes (often just called \"admonitions\") in Jupyter Notebooks are special formatted blocks, typically implemented via Markdown extensions like MyST-Markdown or in tools like Jupyter Book, that allow you to create highlighted callouts in Markdown cells. They draw from reStructuredText (rST) styles and are used to emphasize certain content without disrupting the flow of the notebook.\n",
    "\n",
    "### Primary Reasons for Using Admonitions\n",
    "- **Highlighting Key Information**: They make it easy to spotlight tips, notes, or other advisory content in a visually distinct way, improving readability for educational materials, tutorials, or documentation. For example, a \"note\" admonition might provide additional context or a quick fact.\n",
    "- **Warnings and Cautions**: Admonitions are ideal for alerting users to potential pitfalls, errors, or important caveats, such as deprecated code or safety reminders in data analysis workflows. This helps prevent mistakes in interactive or shared notebooks.\n",
    "- **Structuring Complex Content**: In longer notebooks, they organize information like citations, figures, or side explanations, making the document more professional and easier to navigate. Tools like Jupyter Book extend this for book-like outputs.\n",
    "- **Customization and Rendering**: They support custom fences (e.g., :::) for better compatibility across interfaces, reducing clutter in raw Markdown while enabling rich rendering in HTML or PDF exports.\n",
    "\n",
    "The \"Note\" below is an example of the style for GBR Modelling script repo admonition note. Templated styles can be generated using the `generate_admonition_template` function in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe7e6b",
   "metadata": {},
   "source": [
    "## Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e80db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "from openai import OpenAI\n",
    "# import openai\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import pyperclip\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "import nbformat\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e532b28",
   "metadata": {},
   "source": [
    "## Processing \n",
    "\n",
    "These scripts collectively enable the automated reading, parsing, and AI-driven summarization of Jupyter notebooks by extracting content from code, markdown, and output cells, then using a conversational interface powered by an OpenAI-compatible API to generate initial summaries and handle follow-up queries while maintaining context.\n",
    "\n",
    "### Descriptions of Each Function / Class\n",
    "\n",
    "- **`read_notebook(notebook_path)`**: This function opens and parses a Jupyter notebook file (.ipynb) from the specified path using nbformat, returning a structured NotebookNode object that represents the notebook's contents in version 4 format.\n",
    "\n",
    "- **`extract_content(notebook)`**: This function iterates through all cells in a given notebook, extracting and formatting the source code from code cells (including any text outputs or results), as well as markdown content from markdown cells, and combines them into a single concatenated string separated by descriptive headers like \"# Code cell:\" or \"# Markdown:\".\n",
    "---\n",
    "- The **`NotebookSummarizer`** class is a Python wrapper that facilitates conversational summarization of Jupyter notebooks using the OpenAI API via OpenRouter, maintaining a persistent message history for context-aware initial summaries and follow-up queries while limiting history length to manage token usage.\n",
    "\n",
    "- **`__init__(self, api_key, model=\"openai/gpt-4o\", max_history=10)`** (method of NotebookSummarizer): This constructor initializes the NotebookSummarizer class by creating an OpenAI client configured for OpenRouter, setting the model and history limit, and starting the conversation history with a system prompt that instructs the AI to act as an expert in summarizing Jupyter notebooks while maintaining context.\n",
    "\n",
    "- **`initial_summarize(self, prompt)`** (method of NotebookSummarizer): This method begins the summarization process by optionally copying the provided prompt (notebook content) to the system clipboard, appending it as a user message to the conversation history, and then calling the internal _get_response method to obtain and return the AI's initial summary.\n",
    "\n",
    "- **`follow_up(self, query)`** (method of NotebookSummarizer): This method allows for subsequent interactions by appending a new user query to the history, trimming the history if it exceeds the maximum length by removing the oldest user-assistant pairs (while preserving the system prompt), and then retrieving and returning the AI's response based on the updated context.\n",
    "\n",
    "- **`_get_response(self)`** (method of NotebookSummarizer): This private method handles the core API interaction by sending the current conversation history to the OpenAI chat completions endpoint via the configured client, extracting the assistant's response text (with fallback handling for different response formats), appending it to the history, and returning it, while including optional headers and a high max_tokens limit for detailed outputs; it raises an exception if the extraction fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53aaec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_notebook(notebook_path):\n",
    "    \"\"\"\n",
    "    Reads a Jupyter notebook file and returns its content.\n",
    "    \n",
    "    Args:\n",
    "        notebook_path (str): Path to the .ipynb file\n",
    "        \n",
    "    Returns:\n",
    "        nbformat.NotebookNode: Parsed notebook object\n",
    "    \"\"\"\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as file:\n",
    "        return nbformat.read(file, as_version=4)\n",
    "    \n",
    "\n",
    "def extract_content(notebook):\n",
    "    \"\"\"\n",
    "    Extracts text from code and markdown cells in a notebook.\n",
    "    \n",
    "    Args:\n",
    "        notebook (nbformat.NotebookNode): The notebook to process\n",
    "        \n",
    "    Returns:\n",
    "        str: Combined content from all cells\n",
    "    \"\"\"\n",
    "    content_parts = []\n",
    "    \n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'code':\n",
    "            # Include both the code and any text outputs\n",
    "            content_parts.append(f\"# Code cell:\\n{cell.source}\\n\")\n",
    "            if 'outputs' in cell and cell.outputs:\n",
    "                for output in cell.outputs:\n",
    "                    if output.output_type == 'stream' and 'text' in output:\n",
    "                        content_parts.append(f\"# Output:\\n{output.text}\\n\")\n",
    "                    elif output.output_type == 'execute_result' and 'data' in output:\n",
    "                        if 'text/plain' in output.data:\n",
    "                            content_parts.append(f\"# Result:\\n{output.data['text/plain']}\\n\")\n",
    "        elif cell.cell_type == 'markdown':\n",
    "            content_parts.append(f\"# Markdown:\\n{cell.source}\\n\")\n",
    "    \n",
    "    return \"\\n\".join(content_parts)\n",
    "\n",
    "\n",
    "class NotebookSummarizer:\n",
    "    \"\"\"\n",
    "    A conversational wrapper for summarizing notebooks with persistent context.\n",
    "    Manages message history for follow-up queries.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key, model=\"openai/gpt-4o\", max_history=10):\n",
    "        self.client = OpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=api_key,\n",
    "        )\n",
    "        self.model = model\n",
    "        self.history = []  # List of {\"role\": str, \"content\": str}\n",
    "        self.max_history = max_history  # Limit to prevent token overflow\n",
    "        # Initial system message\n",
    "        system_prompt = 'You are an expert at analyzing and summarizing Jupyter notebooks for data science and programming contexts. Maintain context from previous interactions.'\n",
    "        self.history.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    def initial_summarize(self, prompt):\n",
    "        \"\"\"\n",
    "        Start the conversation with the initial notebook content.\n",
    "        \n",
    "        Args:\n",
    "            content (str): The notebook content to summarize.\n",
    "        \"\"\"\n",
    "        # Build initial prompt (your original, but without repeating in follow-ups)\n",
    "\n",
    "        pyperclip.copy(prompt)  # Optional: Copy for manual use\n",
    "        self.history.append({\"role\": \"user\", \"content\": prompt})\n",
    "        return self._get_response()\n",
    "    \n",
    "    def follow_up(self, query):\n",
    "        \"\"\"\n",
    "        Send a follow-up query using the existing context.\n",
    "        \n",
    "        Args:\n",
    "            query (str): The follow-up question or instruction (e.g., \"Explain the ARD method in more detail\").\n",
    "        \n",
    "        Returns:\n",
    "            str: The assistant's response.\n",
    "        \"\"\"\n",
    "        self.history.append({\"role\": \"user\", \"content\": query})\n",
    "        # Trim history if too long (remove oldest user/assistant pairs)\n",
    "        while len(self.history) > self.max_history + 1:  # +1 for system\n",
    "            self.history = [self.history[0]] + self.history[2:]  # Skip first user/assistant pair\n",
    "        return self._get_response()\n",
    "    \n",
    "    def _get_response(self):\n",
    "        \"\"\"\n",
    "        Internal method to call the API and extract response.\n",
    "        Uses fallback extraction for robustness.\n",
    "        \"\"\"\n",
    "        def extract_text_from_response(response_obj):\n",
    "            # Same as previous: Extract from ChatCompletion or raw JSON\n",
    "            if hasattr(response_obj, 'choices') and response_obj.choices:\n",
    "                return response_obj.choices[0].message.content\n",
    "            # Fallback recursion (omitted for brevity; use the previous extract_text_from_response)\n",
    "            return \"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.history,\n",
    "                extra_headers={\n",
    "                    \"HTTP-Referer\": \"your-app-url\",  # Optional\n",
    "                    \"X-Title\": \"Notebook Summarizer\",\n",
    "                },\n",
    "                max_tokens=9000,\n",
    "            )\n",
    "            assistant_response = extract_text_from_response(response)\n",
    "            if not assistant_response:\n",
    "                raise ValueError(\"No text extracted from response\")\n",
    "            # Append to history\n",
    "            self.history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "            return assistant_response\n",
    "        except Exception as e:\n",
    "            # Fallback to alpha endpoint if needed (adapt as in previous code)\n",
    "            print(f\"API call failed: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0deeab",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "The `prompt_prefix` is a structured template designed for AI analysis of Jupyter notebooks, directing the generation of a detailed summary organized under six specific headings. \n",
    "\n",
    "In contrast, the `definition_text` provides concise instructions for creating a brief 2-3 line notebook summary to insert into a predefined HTML snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d9069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_prefix = f\"\"\"\n",
    "        Please analyze the following Jupyter notebook content and provide a comprehensive summary.\n",
    "        Organise your response under the following headings:\n",
    "        1. The main purpose and objectives of the notebook\n",
    "        2. Key code logic and functions implemented\n",
    "        3. Important findings or results shown in outputs\n",
    "        4. Overall structure and flow\n",
    "        5. Instructions for use\n",
    "        6. Theoretical Description of Methods\n",
    "\n",
    "        Consistently format the heading like \"## 1. The main purpose and objectives of the notebook\\n\\n\" \n",
    "\n",
    "        Provide a bibliography of web references if used.\n",
    "\n",
    "        Write mathematical expressions using proper LaTeX syntax. Format as inline ($) or display ($$) equations. Do not escape backslashes.\n",
    "        \n",
    "        Be careful to avoid KaTeX parse errors like 'Expected EOF'.\n",
    "\n",
    "        Avoid overuse of bullet or numbered lists.\n",
    "\n",
    "        At the end, add an interesting and possibly relevant fact with a reference if available.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "definition_text = \"\"\"\n",
    "    write a short two to three line summary of the notebook and paste it into the following html snippet\n",
    "    relpacing the field '[short_summary]'\n",
    "\n",
    "> ## <strong style=\"color:#00b8d4; font-size:28px;\">AI Script Summary</strong>\n",
    "> <span style=\"color:#757575; font-size:18px; display:block; margin-top:1px;\">[short_summary] </span> <br/><br/>\n",
    "> <strong>Authors:</strong> F. R. Bennett &nbsp;&nbsp; <br/><br/>\n",
    "> <strong>Date:</strong> 17/10/25  &nbsp;&nbsp; <br/><br/>\n",
    "> <strong>Version:</strong> 1.0<br/><br/>\n",
    "> \n",
    "> <button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples/ishigami_new_legendre.ipynb', 'download')\">Download File</button>\n",
    "> \n",
    "><button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples', 'download')\">Download Folder</button>\n",
    ">\n",
    "><button onclick=\"handleGitHubAction('frbennett', 'shapleyx', 'Examples/ishigami_new_legendre.ipynb', 'open')\">Open on GitHub</button>\n",
    "> <br/><br/>\n",
    "\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.0/jszip.min.js\"></script>\n",
    "<script>\n",
    "async function handleGitHubAction(owner, repo, path, action) {\n",
    "  const apiUrl = `https://api.github.com/repos/${owner}/${repo}/contents/${path}`;\n",
    "  const githubUrl = `https://github.com/${owner}/${repo}/tree/main/${path}`;\n",
    "\n",
    "  if (action === 'open') {\n",
    "    window.open(githubUrl, '_blank');\n",
    "    return;\n",
    "  }\n",
    "\n",
    "  const response = await fetch(apiUrl);\n",
    "  const data = await response.json();\n",
    "\n",
    "  if (Array.isArray(data)) {\n",
    "    // Directory download\n",
    "    const zip = new JSZip();\n",
    "    for (const file of data) {\n",
    "      if (file.type === \"file\") {\n",
    "        const fileRes = await fetch(file.download_url);\n",
    "        const content = await fileRes.text();\n",
    "        zip.file(file.name, content);\n",
    "      }\n",
    "    }\n",
    "    const blob = await zip.generateAsync({ type: \"blob\" });\n",
    "    const link = document.createElement(\"a\");\n",
    "    link.href = URL.createObjectURL(blob);\n",
    "    link.download = `${path.split('/').pop()}.zip`;\n",
    "    link.click();\n",
    "  } else if (data.type === \"file\") {\n",
    "    // Single file download\n",
    "    const decoded = atob(data.content.replace(/\\n/g, ''));\n",
    "    const blob = new Blob([decoded], { type: 'application/octet-stream' });\n",
    "    const link = document.createElement('a');\n",
    "    link.href = URL.createObjectURL(blob);\n",
    "    link.download = data.name;\n",
    "    link.click();\n",
    "  } else {\n",
    "    alert(\"Unsupported content type or path not found.\");\n",
    "  }\n",
    "}\n",
    "</script>\n",
    "\n",
    "\n",
    "                    \"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111450e6",
   "metadata": {},
   "source": [
    "<div class=\"admonition example\" name=\"html-admonition\" style=\"background: rgba(92,107,192,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #5c6bc0; border-color: #5c6bc0; padding-left: 10px; padding-right: 10px;\">\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#5c6bc0;\">&#128221;</i>\n",
    "    <b style=\"color: #5c6bc0;\">Example</b>\n",
    "</p>\n",
    "<p>\n",
    "The <code>summarise_this</code> function serves as a demonstration of the previously defined <code>NotebookSummarizer</code> class and related utilities by taking a path to a Jupyter notebook file and an optional AI model (defaulting to \"google/gemini-2.5-flash-lite\"), reading and extracting its content, constructing a prompt with a predefined prefix, and generating both an initial summary and a follow-up definition response using the summarizer. \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f521928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_this(NOTEBOOK_PATH, model=\"google/gemini-2.5-flash-lite\"):\n",
    "    # Configuration\n",
    "    OPENAI_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")  # Get API key from environment\n",
    "\n",
    "    if not OPENAI_API_KEY:\n",
    "        raise ValueError(\"Please set the OPENAI_API_KEY environment variable\")\n",
    "\n",
    "    if not os.path.exists(NOTEBOOK_PATH):\n",
    "        raise FileNotFoundError(f\"Notebook file not found: {NOTEBOOK_PATH}\")\n",
    "\n",
    "    # Read and process the notebook\n",
    "    print(\"Reading notebook...\")\n",
    "    notebook = read_notebook(NOTEBOOK_PATH)\n",
    "\n",
    "    print(\"Extracting content...\")\n",
    "    notebook_content = extract_content(notebook)\n",
    "\n",
    "    # Build prompt\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    {prompt_prefix}\n",
    "            \n",
    "    Notebook content:\n",
    "    {notebook_content}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    summarizer = NotebookSummarizer(api_key=OPENAI_API_KEY, model=model)\n",
    "    summary = summarizer.initial_summarize(prompt)\n",
    "\n",
    "    \n",
    "    definition_response = summarizer.follow_up(definition_text)\n",
    "\n",
    "    # Usage\n",
    "\n",
    "    return summary, definition_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba22ed8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a2b358",
   "metadata": {},
   "source": [
    "<div class=\"admonition example\" name=\"html-admonition\" style=\"background: rgba(92,107,192,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #5c6bc0; border-color: #5c6bc0; padding-left: 10px; padding-right: 10px;\">\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#5c6bc0;\">&#128221;</i>\n",
    "    <b style=\"color: #5c6bc0;\">Example</b>\n",
    "</p>\n",
    "<p>\n",
    "Now, pulling it all together and building a summary of this notebook. The final composed result is displayed using the <code>Markdown</code> function and is saved to the clipboard using <code>pyperclip</code> to be pasted directly into a markdown document or cell. \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ff54069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading notebook...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'd:\\\\gdrive\\\\My Drive\\\\Work Projects\\\\Coding_Projects\\\\script_repo\\\\scripts\\\\utilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m model=\u001b[33m\"\u001b[39m\u001b[33mx-ai/grok-4-fast\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m summary, definition_response = \u001b[43msummarise_this\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m all_result = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33m \u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mdefinition_response\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33m# Detailed Summary\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m---\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;132;01m{\u001b[39;00msummary\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     11\u001b[39m pyperclip.copy(all_result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36msummarise_this\u001b[39m\u001b[34m(NOTEBOOK_PATH, model)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Read and process the notebook\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mReading notebook...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m notebook = \u001b[43mread_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNOTEBOOK_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExtracting content...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m notebook_content = extract_content(notebook)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mread_notebook\u001b[39m\u001b[34m(notebook_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_notebook\u001b[39m(notebook_path):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Reads a Jupyter notebook file and returns its content.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \u001b[33;03m        nbformat.NotebookNode: Parsed notebook object\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnotebook_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m nbformat.read(file, as_version=\u001b[32m4\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\frbem\\miniforge3\\envs\\dev_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'd:\\\\gdrive\\\\My Drive\\\\Work Projects\\\\Coding_Projects\\\\script_repo\\\\scripts\\\\utilities'"
     ]
    }
   ],
   "source": [
    "model=\"x-ai/grok-4-fast\"\n",
    "\n",
    "summary, definition_response = summarise_this(current_path, model=model)\n",
    "\n",
    "all_result = f\"\"\" \n",
    "{definition_response}\n",
    "# Detailed Summary\n",
    "---\n",
    "{summary}\n",
    "\"\"\"\n",
    "pyperclip.copy(all_result)\n",
    "Markdown(all_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c6327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cce0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading notebook...\n",
      "Extracting content...\n"
     ]
    }
   ],
   "source": [
    "NOTEBOOK_PATH = 'ai_script_summary.ipynb'\n",
    "# Read and process the notebook\n",
    "print(\"Reading notebook...\")\n",
    "notebook = read_notebook(NOTEBOOK_PATH)\n",
    "\n",
    "print(\"Extracting content...\")\n",
    "notebook_content = extract_content(notebook)\n",
    "\n",
    "# Build prompt\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{prompt_prefix}\n",
    "        \n",
    "Notebook content:\n",
    "{notebook_content}\n",
    "\n",
    "\"\"\"\n",
    "pyperclip.copy(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb8f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy(all_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aef3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.md\", \"w\") as file:\n",
    "    file.write(all_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4bb581",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d6f2fc",
   "metadata": {},
   "source": [
    "\n",
    "> ## <strong style=\"color:#00b8d4; font-size:28px;\">AI Script Summary</strong>\n",
    "> <span style=\"color:#757575; font-size:18px; display:block; margin-top:1px;\">This notebook implements an automated Jupyter notebook summarization tool that extracts content from code and markdown cells, then processes it through various large language models via the OpenRouter API. It provides structured summaries with consistent formatting and includes utilities for result export and prompt debugging. The system supports multiple AI models and handles the complete pipeline from notebook parsing to formatted output generation. </span>\n",
    ">\n",
    "> <strong>Authors:</strong> F. R. Bennett &nbsp;&nbsp; <br/><br/>\n",
    "> <strong>Date:</strong> 17/10/25  &nbsp;&nbsp; <br/><br/>\n",
    "> <strong>Version:</strong> 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e86291",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f173af2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7e715f0",
   "metadata": {},
   "source": [
    "> ## <strong style=\"color:#00b8d4; font-size:28px;\">AI Script Summary</strong>\n",
    "> <span style=\"color:#757575; font-size:18px; display:block; margin-top:1px;\">This Jupyter notebook conducts global sensitivity analysis on the Ishigami function, a nonlinear benchmark for uncertainty quantification, using RS-HDMR from the shapleyx library. It generates Sobol-sampled inputs, fits a sparse second-order polynomial surrogate via ARD with cross-validation, and derives sensitivity indices like Sobol, SHAP, PAWN, HX, and deltaX to assess variable contributions and interactions. Key findings reveal X2's strong main effect (Sobol 0.446) and X1-X3 interaction (0.240), with near-perfect model reconstruction (R² ≈ 1.000). </span>\n",
    ">\n",
    "> <strong>Authors:</strong> F. R. Bennett &nbsp;&nbsp; <br/><br/>\n",
    "> <strong>Date:</strong> 17/10/25  &nbsp;&nbsp; <br/><br/>\n",
    "> <strong>Version:</strong> 1.0<br/><br/>\n",
    "> <a href=\"https://github.com/frbennett/shapleyx/blob/main/Examples/ishigami_new_legendre.ipynb\">View notebook in Github</a>\n",
    "> <br/><br/>\n",
    "> <a href=\"https://minhaskamal.github.io/DownGit/#/home?url=https://github.com/frbennett/shapleyx/blob/main/Examples/ishigami_new_legendre.ipynb\">Download notebook</a>\n",
    "> <br/><br/>\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b4ff3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b146031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ac49814",
   "metadata": {},
   "source": [
    "> ## <span style=\"font-size: 25px; line-height: 1.0; color: #ff7043; margin-right: 100px;\">&#9888;<span> <strong style=\"color: #ff7043;\">Caution</strong>\n",
    "> Purpose: sssss\n",
    "> <br/><br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c216e66",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4; border-color: #00b8d4; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b style=\"color: #9888;\">&#9998 Note</b>\n",
    "</p>\n",
    "\n",
    "See <a href=\"../faq/cyclical-features-time-series.html\" target=\"_blank\">Cyclical features in time series forecasting</a> for a more detailed description of strategies for encoding cyclic features.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b66b06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f659df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_admonition_template(admonition_type: str, content: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Generate an HTML admonition note template based on the specified type.\n",
    "    \n",
    "    Args:\n",
    "        admonition_type (str): The type of admonition (e.g., \"Note\", \"Tip\").\n",
    "        content (str, optional): The content to insert inside the admonition. Defaults to a placeholder.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated HTML string for the admonition.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the admonition_type is not in ADMONITION_TEMPLATES.\n",
    "    \"\"\"\n",
    "    ADMONITION_TEMPLATES = {\n",
    "        \"Note\": {\"icon\": \"&#9998;\", \"color\": \"#00b8d4\", \"label_color\": \"#00b8d4\"},\n",
    "        \"Tip\": {\"icon\": \"&#127775;\", \"color\": \"#4caf50\", \"label_color\": \"#4caf50\"},\n",
    "        \"Info\": {\"icon\": \"&#8505;\", \"color\": \"#1976d2\", \"label_color\": \"#1976d2\"},\n",
    "        \"Success\": {\"icon\": \"&#10004;\", \"color\": \"#2e7d32\", \"label_color\": \"#2e7d32\"},\n",
    "        \"Warning\": {\"icon\": \"&#9888;\", \"color\": \"#fbc02d\", \"label_color\": \"#fbc02d\"},\n",
    "        \"Danger\": {\"icon\": \"&#10060;\", \"color\": \"#d32f2f\", \"label_color\": \"#d32f2f\"},\n",
    "        \"Caution\": {\"icon\": \"&#9888;\", \"color\": \"#ff7043\", \"label_color\": \"#ff7043\"},\n",
    "        \"Question\": {\"icon\": \"&#10067;\", \"color\": \"#6a1b9a\", \"label_color\": \"#6a1b9a\"},\n",
    "        \"Hint\": {\"icon\": \"&#128161;\", \"color\": \"#00897b\", \"label_color\": \"#00897b\"},\n",
    "        \"Example\": {\"icon\": \"&#128221;\", \"color\": \"#5c6bc0\", \"label_color\": \"#5c6bc0\"},\n",
    "        \"Important\": {\"icon\": \"&#128295;\", \"color\": \"#455a64\", \"label_color\": \"#455a64\"},\n",
    "        \"Deprecated\": {\"icon\": \"&#128221;\", \"color\": \"#ff5722\", \"label_color\": \"#ff5722\"},\n",
    "        \"Experimental\": {\"icon\": \"&#9881;\", \"color\": \"#9c27b0\", \"label_color\": \"#9c27b0\"},\n",
    "        \"Performance\": {\"icon\": \"&#128200;\", \"color\": \"#3f51b5\", \"label_color\": \"#3f51b5\"},\n",
    "        \"Reference\": {\"icon\": \"&#128214;\", \"color\": \"#607d8b\", \"label_color\": \"#607d8b\"},\n",
    "    }\n",
    "    \n",
    "    if admonition_type not in ADMONITION_TEMPLATES:\n",
    "        raise ValueError(f\"Admonition type '{admonition_type}' not supported. Available types: {list(ADMONITION_TEMPLATES.keys())}\")\n",
    "    \n",
    "    template = ADMONITION_TEMPLATES[admonition_type]\n",
    "    icon = template[\"icon\"]\n",
    "    color = template[\"color\"]\n",
    "    label_color = template[\"label_color\"]\n",
    "    \n",
    "    # Convert hex color to RGB for background\n",
    "    def hex_to_rgb(hex_color: str) -> tuple:\n",
    "        hex_color = hex_color.lstrip('#')\n",
    "        return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    \n",
    "    r, g, b = hex_to_rgb(color)\n",
    "    bg_style = f\"background: rgba({r},{g},{b},.1);\"\n",
    "    \n",
    "    # Default content if none provided\n",
    "    if content is None:\n",
    "        content = f\"Replace this with your {admonition_type.lower()} content.\"\n",
    "    \n",
    "    # Build the HTML\n",
    "    html = f'''<div class=\"admonition {admonition_type.lower()}\" name=\"html-admonition\" style=\"{bg_style} padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid {color}; border-color: {color}; padding-left: 10px; padding-right: 10px;\">\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:{color};\">{icon}</i>\n",
    "    <b style=\"color: {label_color};\">{admonition_type}</b>\n",
    "</p>\n",
    "<p>{content}</p>\n",
    "</div>'''\n",
    "    \n",
    "    return html\n",
    "\n",
    "# Example usage:\n",
    "# print(generate_admonition_template(\"Note\", \"See <a href='../faq/example.html' target='_blank'>Example</a> for details.\"))\n",
    "# Output: The full HTML for a Note admonition with the provided content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = generate_admonition_template('Note', 'Thi is a string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57043fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ca6234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c3fd735",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4; border-color: #00b8d4; padding-left: 10px; padding-right: 10px;\">\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00b8d4;\">&#9998;</i>\n",
    "    <b style=\"color: #00b8d4;\">Note</b>\n",
    "</p>\n",
    "<p>Thi is a string</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3dc58e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
